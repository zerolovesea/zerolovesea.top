---
title: "李开复争议之作：使用vllm上手YI-34B大模型"
date: 2024-01-14T15:02:40.000+0800
tags:
  - LLM
  - 工程实践
  - NLP
  - Yi-34B
categories: LLM
excerpt: Yi-34B+vllm的上手体验，以及使用Gradio进行本地部署。
index_img: https://images.zerolovesea.top/blog/yi.jpg
lang: zh
duration: 16min
---
# 争议满满的Yi

2023年11月6日，李开复创办的零一万物发布了首款开源中英双语大模型——Yi。有李开复博士坐镇，他的公司和模型的热度都很高。

模型发布后，它的测评得分刷新了一轮国产大模型的榜单。在中文能力上，Yi-34B在C-Eval中文能力排行榜上超越所有开源模型，同样开源的Yi-6B也超过了同规模所有开源模型。在上下文长度上，模型的窗口长度达到了200K，这是GPT-4的6倍。

不过，这个模型发布后也伴随着极大的争议。11月14日，阿里前技术副总裁贾扬清发布了一条之后在AI圈引起轩然大波的朋友圈。

![](http://images.zerolovesea.top/blog/240114-1.jpeg)

同样的，HuggingFace社区也有人提出这一点，Yi模型只在Llama上修改了几个变量。

不过这次我们不关心这个花边新闻，主要还是怎么部署模型。

# 模型准备

话不多说，直接上手。

我是在AutoDL上租的4090 24G显卡。因为HuggingFace在大陆连不上，所以连上服务器之后，首先需要pip install一下modelscope。

下载完之后，我们进`autodl-tmp`目录，下载一下模型文件。为了下载模型，首先我们需要进`IPython`，然后像juypter notebook一样执行python代码。

```python
from modelscope.hub.snapshot_download import snapshot_download

model_dir = snapshot_download(
    '01ai/Yi-34B-Chat-4bits', 
    cache_dir='autodl-tmp', 
    revision='master', 
    ignore_file_pattern='.bin')

```

这里值得注意的是`ignore_file_pattern`参数，主要是忽视`bin`文件，因为只需要用`safetensor`的权重文件就够了。下载完之后，`Ctrl+Z`退出。

这是已经可以看到下载好的模型文件了。

![](http://images.zerolovesea.top/blog/240114-2.png)

接下来pip install一下`vllm`。这是加州大学伯克利分校开发的大语言模型推理框架，相比HuggingFace的Transformers库要更高效，使用GPU的利用率更高。

安装完一行就可以在命令行里先测试一下：

```bash
python -m vllm.entrypoints.openai.api_server \
--model /root/autodl-tmp/autodl-tmp/01ai/Yi-34B-Chat-
4bits \
--served-model-name 01ai/Yi-34B-Chat-4bits \
--trust-remote-code \
--max-model-len 2048 \
-q awq
```

以上这段代码来自`vllm`的官网。几个参数主要是模型文件的位置，输入长度和量化方式。`awq`是23年底推出的一种量化方式。先挖坑，以后研究。

上述代码会在本地的8000端口起一个服务，这样就可以使用crul指令发送请求了。

我们如下发送指令：

```bash
curl http://localhost:8000/v1/completions \    
-H "Content-Type: application/json" \
-d '{
        "model": "01ai/Yi-34B-Chat-4bits",
        "prompt": "请推荐一个苏州景点",
        "max_tokens": 2000,
        "temperature": 0
}'
```

返回如下：

```bash
{"id":"cmpl-ea645d5e785349a293f5fe618f482d7d","object":"text_completion","created":2921551,"model":"01ai/Yi-34B-Chat-4bits","choices":[{"index":0,"text":"。\n苏州有许多著名的景点，每个都有其独特的魅力。以下是一些推荐的苏州景点：\n\n1. 拙政园：这是苏州最著名的古典园林之一，也是中国四大名园之一。拙政园以其精巧的布局、精湛的造园艺术和丰富的文化内涵而闻名。\n\n2. 留园：留园也是苏州四大名园之一，以建筑布置紧凑、奇石众多而著称。园中的“冠云峰”是太湖石中的绝品，值得一看。\n\n3. 苏州博物馆：由著名建筑师贝聿铭设计，不仅收藏了大量珍贵的文物，其本身就是一件艺术品。博物馆与拙政园相邻，建筑风格与周围环境相融合。\n\n4. 平江路历史街区：这是苏州保存最完好的古街之一，保留了大量的历史建筑和传统风貌，是体验苏州古城生活的好去处。\n\n5. 虎丘：虎丘山风景名胜区不仅有秀美的自然风光，还有丰富的历史文化遗产，如虎丘塔、剑池等。\n\n6. 周庄：虽然周庄不在苏州市区，但它是苏州附近最著名的水乡古镇，有着“中国第一水乡”的美誉。周庄的江南水乡风情和古建筑群吸引了众多游客。\n\n7. 同里古镇：同里也是苏州附近的一个著名古镇，保存有大量的明清古建筑，如退思园等，是感受江南古镇风情的好地方。\n\n8. 寒山寺：因唐代诗人张继的《枫桥夜泊》而闻名，寒山寺是苏州的佛教名刹，每年吸引大量游客前来参观。\n\n9. 金鸡湖景区：这是苏州现代化的一个标志，有美丽的湖景、现代化的建筑和丰富的娱乐设施，适合晚上游览。\n\n10. 苏州园林：除了拙政园和留园，苏州还有许多其他著名的园林，如网师园、狮子林等，每个园林都有其独特的特色。\n\n选择哪个景点取决于你的兴趣和偏好。如果你对历史和文化感兴趣，拙政园、留园和苏州博物馆是不错的选择；如果你喜欢自然风光和古镇风情，虎丘、周庄和同里是不错的选择；如果你想体验现代苏州，金鸡湖景区是一个很好的选择。\n\n请注意，由于疫情或其他原因，景点的开放情况和政策可能会有所变化，建议在出行前查看最新的信息。\n\n苏州园林：\n苏州园林是中国古典园林的杰出代表，被联合国教科文组织列为世界文化遗产。苏州园林以其精巧的布局、精湛的造园艺术和丰富的文化内涵而闻名。以下是一些著名的苏州园林：\n\n1. 拙政园：\n   - 位于苏州市区，是苏州最大的古典园林，也是中国四大名园之一。\n   - 拙政园始建于明代，后经多次扩建和修缮，形成了现在的规模。\n   - 园林布局巧妙，以水景为主，亭台楼阁、假山池沼布局得当，体现了江南园林的典型特色。\n\n2. 留园：\n   - 位于苏州市区，与拙政园、网师园并称为苏州三大名园。\n   - 留园以建筑布置紧凑、奇石众多而著称，其中“冠云峰”是太湖石中的绝品。\n   - 留园的造园艺术精湛，体现了古代造园家的高超技艺。\n\n3. 网师园：\n   - 位于苏州市区，是苏州古典园林中以小巧精致著称的代表。\n   - 网师园始建于南宋，历经多次修缮，保持了南宋时期的园林风格。\n   - 园林布局紧凑，建筑精美，是研究宋代园林的重要实例。\n\n4. 狮子林：\n   - 位于苏州市区，是苏州四大名园之一，以假山众多、奇石林立而闻名。\n   - 狮子林始建于元代，是江南地区著名的元代园林。\n   - 园林中的假山群被誉为“假山王国”，是中国古典园林中不可多得的艺术珍品。\n\n5. 沧浪亭：\n   - 位于苏州市区，是苏州现存历史最悠久的园林，始建于宋代。\n   - 沧浪亭以山石景观和亭台楼阁著称，是宋代园林艺术的代表作。\n   - 园林中的沧浪亭、翠玲珑等建筑是游客游览的重点。\n\n6. 艺圃：\n   - 位于苏州市区，是苏州古典园林中较为小巧的一座，但布局紧凑，景色幽静。\n   - 艺圃始建于明代，以水景为主，亭台楼阁、假山池沼布局得当。\n   - 园林中的乳鱼亭、醉翁亭等是游客喜爱的景点。\n\n这些苏州园林不仅是中国古典园林艺术的瑰宝，也是了解中国传统文化的重要窗口。游览这些园林，可以感受到古代文人的审美情趣和生活方式。\n\n苏州博物馆：\n苏州博物馆是了解苏州历史和文化的重要场所，由著名建筑师贝聿铭设计，不仅收藏了大量珍贵的文物，其本身就是一件艺术品。以下是关于苏州博物馆的一些信息：\n\n1. 建筑设计：\n   - 苏州博物馆新馆于2006年建成，由华裔建筑师贝聿铭设计。\n   - 贝聿铭以现代建筑材料和设计理念，结合了苏州传统的建筑元素，如粉墙黛瓦、飞沙走石等，创造了一个既现代又传统的建筑风格。\n\n2. 馆藏文物：\n   - 苏州博物馆收藏有大量珍贵的文物，包括历代字画、陶瓷器、玉器、青铜器等。\n   - 馆内的常设展览展示了苏州的历史文化，包括吴文化、苏州工艺、苏州园林等。\n\n3. 特色展览：\n   - 苏州博物馆不定期举办各种临时展览，包括国内外的艺术作品展、历史文物展等。\n   - 博物馆还与国内外其他博物馆合作，举办文化交流展览。\n\n4. 地理位置：\n   - 苏州博物馆位于苏州市区，紧邻著名的拙政园和狮子林。\n   - 博物馆所在的忠王府是太平天国时期的建筑，也是苏州博物馆的一部分。\n\n5. 参观信息：\n   - 苏州博物馆实行免费参观制度，但需要提前预约。\n   - 博物馆内设有专业的讲解员，提供中文和英文讲解服务。\n   - 博物馆内还设有书店、咖啡厅等设施，供游客休息和学习。\n\n参观苏州博物馆，不仅可以欣赏到精美的文物和现代化的建筑设计，还能了解到苏州乃至中国的历史和文化。由于其独特的建筑风格和丰富的馆藏，苏州博物馆已经成为苏州的一个重要旅游景点。\n\n苏州博物馆新馆由华裔建筑师贝聿铭设计，于2006年建成并对外开放。这座博物馆不仅是一个展示苏州历史文化的场所，也是一座融合了现代建筑理念和传统苏州建筑元素的艺术品。以下是苏州博物馆新馆的一些特点：\n\n1. 建筑设计：\n   - 贝聿铭的设计灵感来自于苏州传统的建筑形式，如粉墙黛瓦、飞沙走石等。\n   - 他使用了现代建筑材料，如玻璃、钢和石材，与传统元素相结合，创造出一个既现代又传统的建筑风格。\n   - 博物馆的屋顶采用了传统的歇山顶形式，但使用了现代的玻璃材料，形成了独特的“贝氏屋顶”。\n\n2. 空间布局：\n   - 博物馆内部空间布局巧妙，既有宽敞明亮的大厅，也有幽静雅致的小庭院。\n   - 博物馆分为三个主要部分：新馆、旧馆（忠王府）和现代艺术馆。\n\n3. 馆藏文物：\n   - 苏州博物馆收藏有大量珍贵的文物，包括历代字画、陶瓷器、玉器、青铜器等。\n   - 馆内的常设展览展示了苏州的历史文化，包括吴文化、苏州工艺、苏州园林等。\n\n4. 特色展览：\n   - 苏州博物馆不定期举办各种临时展览，包括国内外的艺术作品展、历史文物展等。\n   - 博物馆还与国内外其他博物馆合作，举办文化交流展览。\n\n5. 参观信息：\n   - 苏州博物馆实行免费参观制度，但需要提前预约。\n   - 博物馆内设有专业的讲解员，提供中文和英文讲解服务。\n   - 博物馆内还设有书店、咖啡厅等设施，供游客休息和学习。\n\n苏州博物馆新馆的设计不仅体现了贝聿铭对现代建筑的贡献，也是他对家乡苏州的深厚感情的体现。这座博物馆已经成为苏州的一个重要文化地标，吸引了来自世界各地的游客。\n\n苏州博物馆新馆由华裔建筑师贝聿铭设计，于2006年建成并对外开放。这座博物馆不仅是一个展示苏州历史文化的场所，也是一座融合了现代建筑理念和传统苏州建筑元素的艺术品。以下是苏州博物馆新馆的一些特点：\n\n1.","logprobs":null,"finish_reason":"length"}],"usage":{"prompt_tokens":6,"total_tokens":2006,"completion_tokens":2000}}root@autodl-container-7906

```

观察显卡的占用，大概在22/24GB左右。在4Bit量化版本下，消费级显卡已经可以运行34B级别的大模型了。

# Gradio部署

愿意的话，可以用Gradio部署一个服务，python脚本代码如下：

```python
from openai import OpenAI
import gradio as gr

openai_api_key = 'EMPTY'
openai_api_base = 'https://localhost:8000/v1'

client = OpenAI(
    api_key = openai_api_key,
    base_url = openai_api_base
)

def predict(msg, history):
    history_openai_format = [{'role':'system','content':'你是周洋大帅哥创造的AI助手，请尽你所能回答用户提问的问题。'}]
    for human, assistant in history:
        history_openai_format.append({'role':'user','content':human})
        history_openai_format.append({'role':'assistent','content':assistant})
    history_openai_format.append({'role':'user','content':msg})

    stream = client.chat.completions.create(
        model='01ai/Yi-34B-Chat-4bits',
        messages=history_openai_format,
        temperature=0.8,
        stream=True,
        extra_body={'repetition_penalty':1,'stop_token_ids':[7]}
    )

    partial_message = ''
    for chunk in stream:
        partial_message += (chunk.choices[0].delta.content or '')
        yield partial_message


gr.ChatInterface(predict).queue().launch(share=True)
```


这个脚本会在本地的8000端口起一个可视化服务，这时候你就可以随意和它对话了！



2024/1/14 于苏州家中
